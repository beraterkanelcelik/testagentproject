services:
  # PostgreSQL Database with pgvector extension
  db:
    image: pgvector/pgvector:pg16
    container_name: postgres-db
    environment:
      POSTGRES_DB: ${DB_NAME:-ai_agents_db}
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_INITDB_ARGS: "-E UTF8"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infra/postgres/extensions.sql:/docker-entrypoint-initdb.d/extensions.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - app-network

  # Django Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: django-backend
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - DEBUG=True
      - DB_HOST=db
      - DB_NAME=${DB_NAME:-ai_agents_db}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - DB_PORT=5432
      # Limit Python memory usage
      - PYTHONHASHSEED=0
      - MALLOC_ARENA_MAX=2
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPYCACHEPREFIX=/tmp/pycache
      # Disable Langfuse tracing to prevent OTEL exporter errors
      - LANGFUSE_ENABLED=false
    volumes:
      # Mount code for development (hot reload)
      - ./backend:/app
      # Exclude cache files and logs for better performance and memory usage
      - /app/__pycache__
      - /app/staticfiles
      - /app/logs
      - /app/*.pyc
      - /app/**/*.pyc
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    stdin_open: true
    tty: true
    networks:
      - app-network
    # Memory limits (using mem_limit for regular compose, not Swarm)
    mem_limit: 2g
    mem_reservation: 1g
    # Hot-reload disabled - restart container manually for code changes
    command: sh -c "python manage.py migrate --noinput && uvicorn app.asgi:application --host 0.0.0.0 --port 8000 --workers 1 --limit-max-requests 1000"

  # Frontend (React + Vite)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: react-frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:8000
      # Node.js memory limit (lowered to 512MB to reduce pressure during startup)
      - NODE_OPTIONS=--max-old-space-size=512
    volumes:
      # Mount code for development (hot reload disabled - restart container for changes)
      - ./frontend:/app
      - /app/node_modules
      - /app/dist
      # Persist Vite cache to avoid re-optimization
      - vite_cache:/app/.vite
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - app-network
    # Memory limits (using mem_limit for regular compose, not Swarm)
    mem_limit: 2g
    mem_reservation: 1g

  # Nginx (Reverse Proxy - Optional for production)
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    ports:
      - "80:80"
    volumes:
      - ./infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./backend/staticfiles:/usr/share/nginx/html/static:ro
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
    networks:
      - app-network

  # Langfuse (AI Tracing & Observability) - v3 Official Setup
  # Based on: https://github.com/langfuse/langfuse/blob/main/docker-compose.yml
  # Adapted for our network and shared PostgreSQL database
  
  langfuse-worker:
    image: docker.io/langfuse/langfuse-worker:3
    container_name: langfuse-worker
    restart: always
    profiles: ["observability"]
    mem_limit: 512m
    mem_reservation: 256m
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
      redis:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    ports:
      - 127.0.0.1:3030:3030
    environment:
      NEXTAUTH_URL: ${NEXTAUTH_URL:-http://localhost:3001}
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@db:5432/langfuse_db
      SALT: ${SALT:-mysalt}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:-0000000000000000000000000000000000000000000000000000000000000000}
      TELEMETRY_ENABLED: ${TELEMETRY_ENABLED:-true}
      LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: ${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-true}
      CLICKHOUSE_MIGRATION_URL: clickhouse://clickhouse:9000
      CLICKHOUSE_URL: http://clickhouse:8123
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-clickhouse}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
      CLICKHOUSE_CLUSTER_ENABLED: ${CLICKHOUSE_CLUSTER_ENABLED:-false}
      LANGFUSE_USE_AZURE_BLOB: ${LANGFUSE_USE_AZURE_BLOB:-false}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: ${LANGFUSE_S3_EVENT_UPLOAD_BUCKET:-langfuse}
      LANGFUSE_S3_EVENT_UPLOAD_REGION: ${LANGFUSE_S3_EVENT_UPLOAD_REGION:-auto}
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE:-true}
      LANGFUSE_S3_EVENT_UPLOAD_PREFIX: ${LANGFUSE_S3_EVENT_UPLOAD_PREFIX:-events/}
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: ${LANGFUSE_S3_MEDIA_UPLOAD_BUCKET:-langfuse}
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: ${LANGFUSE_S3_MEDIA_UPLOAD_REGION:-auto}
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE:-true}
      LANGFUSE_S3_MEDIA_UPLOAD_PREFIX: ${LANGFUSE_S3_MEDIA_UPLOAD_PREFIX:-media/}
      LANGFUSE_S3_BATCH_EXPORT_ENABLED: ${LANGFUSE_S3_BATCH_EXPORT_ENABLED:-false}
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: ${LANGFUSE_S3_BATCH_EXPORT_BUCKET:-langfuse}
      LANGFUSE_S3_BATCH_EXPORT_PREFIX: ${LANGFUSE_S3_BATCH_EXPORT_PREFIX:-exports/}
      LANGFUSE_S3_BATCH_EXPORT_REGION: ${LANGFUSE_S3_BATCH_EXPORT_REGION:-auto}
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://minio:9000
      LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT: http://localhost:9000
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: ${LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE:-true}
      LANGFUSE_INGESTION_QUEUE_DELAY_MS: ${LANGFUSE_INGESTION_QUEUE_DELAY_MS:-}
      LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS: ${LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS:-}
      REDIS_HOST: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_AUTH: ${REDIS_AUTH:-myredissecret}
      REDIS_TLS_ENABLED: ${REDIS_TLS_ENABLED:-false}
      REDIS_TLS_CA: ${REDIS_TLS_CA:-/certs/ca.crt}
      REDIS_TLS_CERT: ${REDIS_TLS_CERT:-/certs/redis.crt}
      REDIS_TLS_KEY: ${REDIS_TLS_KEY:-/certs/redis.key}
      EMAIL_FROM_ADDRESS: ${EMAIL_FROM_ADDRESS:-}
      SMTP_CONNECTION_URL: ${SMTP_CONNECTION_URL:-}
    networks:
      - app-network

  # Langfuse Web UI - DISABLED due to OOM (JavaScript heap out of memory)
  # The container repeatedly crashes with memory errors even with 512m limit.
  # To re-enable: uncomment this service and increase mem_limit to at least 1g
  # langfuse-web:
  #   image: docker.io/langfuse/langfuse:3
  #   container_name: langfuse-web
  #   restart: always
  #   profiles: ["observability"]
  #   mem_limit: 512m
  #   mem_reservation: 256m
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     minio:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #     clickhouse:
  #       condition: service_healthy
  #   ports:
  #     - 3001:3000
  #   environment:
  #     NEXTAUTH_URL: ${NEXTAUTH_URL:-http://localhost:3001}
  #     DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD:-postgres}@db:5432/langfuse_db
  #     SALT: ${SALT:-mysalt}
  #     ENCRYPTION_KEY: ${ENCRYPTION_KEY:-0000000000000000000000000000000000000000000000000000000000000000}
  #     TELEMETRY_ENABLED: ${TELEMETRY_ENABLED:-true}
  #     LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: ${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-true}
  #     CLICKHOUSE_MIGRATION_URL: clickhouse://clickhouse:9000
  #     CLICKHOUSE_URL: http://clickhouse:8123
  #     CLICKHOUSE_USER: ${CLICKHOUSE_USER:-clickhouse}
  #     CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
  #     CLICKHOUSE_CLUSTER_ENABLED: ${CLICKHOUSE_CLUSTER_ENABLED:-false}
  #     LANGFUSE_USE_AZURE_BLOB: ${LANGFUSE_USE_AZURE_BLOB:-false}
  #     LANGFUSE_S3_EVENT_UPLOAD_BUCKET: ${LANGFUSE_S3_EVENT_UPLOAD_BUCKET:-langfuse}
  #     LANGFUSE_S3_EVENT_UPLOAD_REGION: ${LANGFUSE_S3_EVENT_UPLOAD_REGION:-auto}
  #     LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
  #     LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
  #     LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://minio:9000
  #     LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE:-true}
  #     LANGFUSE_S3_EVENT_UPLOAD_PREFIX: ${LANGFUSE_S3_EVENT_UPLOAD_PREFIX:-events/}
  #     LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: ${LANGFUSE_S3_MEDIA_UPLOAD_BUCKET:-langfuse}
  #     LANGFUSE_S3_MEDIA_UPLOAD_REGION: ${LANGFUSE_S3_MEDIA_UPLOAD_REGION:-auto}
  #     LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
  #     LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
  #     LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://minio:9000
  #     LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: ${LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE:-true}
  #     LANGFUSE_S3_MEDIA_UPLOAD_PREFIX: ${LANGFUSE_S3_MEDIA_UPLOAD_PREFIX:-media/}
  #     LANGFUSE_S3_BATCH_EXPORT_ENABLED: ${LANGFUSE_S3_BATCH_EXPORT_ENABLED:-false}
  #     LANGFUSE_S3_BATCH_EXPORT_BUCKET: ${LANGFUSE_S3_BATCH_EXPORT_BUCKET:-langfuse}
  #     LANGFUSE_S3_BATCH_EXPORT_PREFIX: ${LANGFUSE_S3_BATCH_EXPORT_PREFIX:-exports/}
  #     LANGFUSE_S3_BATCH_EXPORT_REGION: ${LANGFUSE_S3_BATCH_EXPORT_REGION:-auto}
  #     LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://minio:9000
  #     LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT: http://localhost:9000
  #     LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
  #     LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-miniosecret}
  #     LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: ${LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE:-true}
  #     LANGFUSE_INGESTION_QUEUE_DELAY_MS: ${LANGFUSE_INGESTION_QUEUE_DELAY_MS:-}
  #     LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS: ${LANGFUSE_INGESTION_CLICKHOUSE_WRITE_INTERVAL_MS:-}
  #     REDIS_HOST: ${REDIS_HOST:-redis}
  #     REDIS_PORT: ${REDIS_PORT:-6379}
  #     REDIS_AUTH: ${REDIS_AUTH:-myredissecret}
  #     REDIS_TLS_ENABLED: ${REDIS_TLS_ENABLED:-false}
  #     REDIS_TLS_CA: ${REDIS_TLS_CA:-/certs/ca.crt}
  #     REDIS_TLS_CERT: ${REDIS_TLS_CERT:-/certs/redis.crt}
  #     REDIS_TLS_KEY: ${REDIS_TLS_KEY:-/certs/redis.key}
  #     EMAIL_FROM_ADDRESS: ${EMAIL_FROM_ADDRESS:-}
  #     SMTP_CONNECTION_URL: ${SMTP_CONNECTION_URL:-}
  #     NEXTAUTH_SECRET: ${NEXTAUTH_SECRET:-mysecret}
  #     LANGFUSE_INIT_ORG_ID: ${LANGFUSE_INIT_ORG_ID:-}
  #     LANGFUSE_INIT_ORG_NAME: ${LANGFUSE_INIT_ORG_NAME:-}
  #     LANGFUSE_INIT_PROJECT_ID: ${LANGFUSE_INIT_PROJECT_ID:-}
  #     LANGFUSE_INIT_PROJECT_NAME: ${LANGFUSE_INIT_PROJECT_NAME:-}
  #     LANGFUSE_INIT_PROJECT_PUBLIC_KEY: ${LANGFUSE_INIT_PROJECT_PUBLIC_KEY:-}
  #     LANGFUSE_INIT_PROJECT_SECRET_KEY: ${LANGFUSE_INIT_PROJECT_SECRET_KEY:-}
  #     LANGFUSE_INIT_USER_EMAIL: ${LANGFUSE_INIT_USER_EMAIL:-}
  #     LANGFUSE_INIT_USER_NAME: ${LANGFUSE_INIT_USER_NAME:-}
  #     LANGFUSE_INIT_USER_PASSWORD: ${LANGFUSE_INIT_USER_PASSWORD:-}
  #   networks:
  #     - app-network

  clickhouse:
    image: docker.io/clickhouse/clickhouse-server
    container_name: clickhouse
    restart: always
    profiles: ["observability"]
    mem_limit: 1g
    mem_reservation: 512m
    user: "101:101"
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-clickhouse}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ports:
      - 127.0.0.1:8123:8123
      - 127.0.0.1:9000:9000
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 1s
    networks:
      - app-network

  minio:
    image: cgr.dev/chainguard/minio
    container_name: minio
    restart: always
    profiles: ["observability"]
    mem_limit: 256m
    mem_reservation: 128m
    entrypoint: sh
    # create the 'langfuse' bucket before starting the service
    command: -c 'mkdir -p /data/langfuse && minio server --address ":9000" --console-address ":9001" /data'
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-miniosecret}
    ports:
      - 9090:9000
      - 127.0.0.1:9091:9001
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 1s
      timeout: 5s
      retries: 5
      start_period: 1s
    networks:
      - app-network

  redis:
    image: docker.io/redis:7
    container_name: redis
    restart: always
    mem_limit: 256m
    mem_reservation: 128m
    command: >
      --requirepass ${REDIS_AUTH:-myredissecret}
      --maxmemory-policy noeviction
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_AUTH:-myredissecret}", "ping"]
      interval: 3s
      timeout: 10s
      retries: 10
    networks:
      - app-network

  # Temporal Server (REQUIRED for workflow execution)
  temporal:
    image: temporalio/auto-setup:1.23
    container_name: temporal
    restart: unless-stopped
    mem_limit: 768m
    mem_reservation: 256m
    depends_on:
      db:
        condition: service_healthy
    environment:
      DB: postgres12
      DB_PORT: 5432
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PWD: ${DB_PASSWORD:-postgres}
      POSTGRES_SEEDS: db
      SKIP_DEFAULT_NAMESPACE_CREATION: "false"
    ports:
      - "7233:7233"
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -q '[t]emporal-server' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 60s
    networks:
      - app-network

  # Temporal UI
  temporal-ui:
    image: temporalio/ui:2.44.0
    container_name: temporal-ui
    restart: unless-stopped
    profiles: ["observability"]
    mem_limit: 128m
    mem_reservation: 64m
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      TEMPORAL_ADDRESS: temporal:7233
    ports:
      - "8080:8080"
    networks:
      - app-network

  # Temporal Worker (REQUIRED for workflow execution)
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: temporal-worker
    restart: unless-stopped
    depends_on:
      temporal:
        condition: service_healthy
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - DEBUG=True
      - DB_HOST=db
      - DB_NAME=${DB_NAME:-ai_agents_db}
      - DB_USER=${DB_USER:-postgres}
      - DB_PASSWORD=${DB_PASSWORD:-postgres}
      - DB_PORT=5432
      - TEMPORAL_ADDRESS=temporal:7233
      - REDIS_URL=redis://redis:6379
      - REDIS_AUTH=${REDIS_AUTH:-myredissecret}
      # Limit Python memory usage
      - PYTHONHASHSEED=0
      - MALLOC_ARENA_MAX=2
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPYCACHEPREFIX=/tmp/pycache
      # Disable Langfuse tracing to prevent OTEL exporter errors
      - LANGFUSE_ENABLED=false
    volumes:
      # Mount code (no file watchers - restart container for changes)
      - ./backend:/app
      - /app/__pycache__
    networks:
      - app-network
    # Memory limits (using mem_limit for regular compose, not Swarm)
    mem_limit: 2g
    mem_reservation: 1g
    command: python -m app.agents.temporal.worker

volumes:
  postgres_data:
  clickhouse_data:
  clickhouse_logs:
  redis_data:
  minio_data:
  vite_cache:

networks:
  app-network:
    driver: bridge
